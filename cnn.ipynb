import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam
from PIL import Image
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.metrics import classification_report, confusion_matrix
import os
# Parameter
img_width, img_height = 150, 150
batch_size = 32
num_classes = 7 # jumlah kelas

# Direktori data
train_data_dir = 'D:\penelitian arya\dataset\Train'
validation_data_dir = 'D:\penelitian arya\dataset\Valid'


# Augmentasi data
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=[0.8, 1.2]
)

validation_datagen = ImageDataGenerator(rescale=1./255)

# Generator untuk membaca gambar dari direktori dataset
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical' # Menggunakan categorical untuk klasifikasi multiklas
)

validation_generator = validation_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical'
)


print("Class indices:", train_generator.class_indices)
# Menggunakan Pre-trained Model (Transfer Learning)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))
base_model.trainable = False

# Membangun model CNN
model = Sequential([

# mengambil ekstraksi fitur seperti warna RGB secara otomatis 
# melalui Conv2D atau lapisan Convolusi pertama
base_model,
GlobalAveragePooling2D(),  # Mengganti Flatten dengan GlobalAveragePooling2D
Dense(512, activation='relu', kernel_regularizer=l2(0.01)),
Dropout(0.5),
Dense(num_classes, activation='softmax')
# Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),
# MaxPooling2D(pool_size=(2, 2)),

# lapisan Convolusi ke dua
# Conv2D(64, (3, 3), activation='relu'),
# MaxPooling2D(pool_size=(2, 2)),

# lapisan Convolusi ke tiga
# Conv2D(128, (3, 3), activation='relu'),
# MaxPooling2D(pool_size=(2, 2)),

# lapisan Convolusi ke empat
# Conv2D(256, (3, 3), activation='relu'),
# MaxPooling2D(pool_size=(2, 2)),

# # lapisan untuk meratakan hasil Convolusi menjadi 1 dimensi
# model.add(Flatten()),
# model.add(Dense(512, activation='relu')),
# model.add(Dropout(0.5)),

# # lapisan output
# model.add(Dense(1, activation='sigmoid'))

# Flatten lapisan untuk meratakan hasil konvolusi menjadi satu dimensi
# Flatten(), 
# Lapisan dense pertama
# Dense(512, activation='relu'),
# Dropout(0.5),
    
# Lapisan output
# Dense(num_classes, activation='softmax')  # Menggunakan softmax untuk klasifikasi multiklas
])

# lapisan untuk mengkompilasi atau menjalankan model
# model.compile(loss='binary_crossentropy',
            #   optimizer='adam',
            #   metrics=['accuracy'])
optimizer = Adam(learning_rate=0.0001)  # Mengatur learning rate
model.compile(optimizer=optimizer, 
                loss='categorical_crossentropy', 
                metrics=['accuracy'])

# Menampilkan ringkasan arsitektur model
model.summary()

# Callbacks
# Early stopping atau pemberhentian secara otomatis 
# jika model yang di train tidak kunjung mengalami peningkatan dalam accuracy-nya
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)



# Melatih model
history = model.fit(
    train_generator,
    epochs = 50,
    # steps_per_epoch=train_generator.samples // batch_size,
    validation_data=validation_generator,
    # validation_steps=validation_generator.samples // batch_size,
    callbacks=[early_stopping, reduce_lr]
)

# Menyimpan model
model.save('plant_disease_cnn.h5')
# Fungsi untuk memprediksi gambar dan menampilkannya dalam grid
def predict_and_show_images_in_folder(folder_path, model, class_labels):
    try:
        image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpeg', '.png', '.jpg'))]
        num_images = len(image_files)
        num_columns = 4
        num_rows = num_images // num_columns + (num_images % num_columns != 0)
        
        plt.figure(figsize=(10, num_rows * 3))
        
        for i, filename in enumerate(image_files):
            image_path = os.path.join(folder_path, filename)
            img = load_img(image_path, target_size=(img_width, img_height))
            img_array = img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)
            img_array /= 254.0

            prediction = model.predict(img_array)
            predicted_class = np.argmax(prediction, axis=1)[0]
            result = class_labels[predicted_class]

            plt.subplot(num_rows, num_columns, i + 1)
            plt.imshow(img)
            plt.title(f'File: {filename}\nPrediction: {result}')
            plt.axis('off')

        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"Error: {e}")

# pemanggilan folder input & model
folder_path = 'D:\penelitian arya\Tes'  
model_path = 'D:\penelitian arya\plant_disease_cnn.h5'  
img_width, img_height = 150, 150

# Daftar label kelas 
class_labels = ['Buah_cabai_sehat', 'Buah Sakit', 'Daun sehat', 'kutu kebul',
                'virus_gemini', 'virus keriting', 'virus mosaic']  

# Memuat model
model = load_model(model_path)

# Memanggil fungsi predict_and_show_images_in_folder
predict_and_show_images_in_folder(folder_path, model, class_labels)
# Menampilkan grafik akurasi dan loss
def plot_training_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs_range = range(len(acc))

    plt.figure(figsize=(7, 4))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.show()
# Plot training history
plot_training_history(history)
# Evaluasi model pada data validasi dan hitung metrik
# def evaluate_model_on_validation(model, validation_generator):
#     validation_generator.reset()
#     Y_pred = model.predict(validation_generator, validation_generator.samples // validation_generator.batch_size + 1)
#     y_pred = np.where(Y_pred > 0.5, 1, 0)  # Binarize predictions
#     y_true = validation_generator.classes  # True labels

#     print('Confusion Matrix')
#     print(confusion_matrix(y_true, y_pred))

#     print('Classification Report')
#     target_names = ['Healthy', 'Diseased']
#     print(classification_report(y_true, y_pred, target_names=target_names))

# Evaluasi model dan tampilkan metrik
# evaluate_model_on_validation(model, validation_generator)
def evaluate_model_on_validation(model, validation_generator):
    # Reset generator
    validation_generator.reset()
    
    # Mendapatkan prediksi dari model
    Y_pred = model.predict(validation_generator, validation_generator.samples // validation_generator.batch_size + 1)
    
    # Mendapatkan indeks dengan probabilitas tertinggi untuk setiap prediksi
    y_pred = np.argmax(Y_pred, axis=1)
    
    # Mendapatkan label asli
    y_true = validation_generator.classes

    # Confusion Matrix
    print('Confusion Matrix')
    cm = confusion_matrix(y_true, y_pred)
    print(cm)

    # Classification Report
    print('Classification Report')
    target_names = list(validation_generator.class_indices.keys())  # Mendapatkan nama kelas dari generator
    print(classification_report(y_true, y_pred, target_names=target_names))

# Evaluasi model dan tampilkan metrik
evaluate_model_on_validation(model, validation_generator)
